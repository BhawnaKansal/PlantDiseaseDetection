{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "     ---------------------------------------- 0.0/82.7 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/82.7 kB ? eta -:--:--\n",
      "     -------------- ----------------------- 30.7/82.7 kB 325.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 82.7/82.7 kB 579.6 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\python312\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (4.66.4)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (2.2.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\python312\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from requests->kaggle) (3.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.2/78.2 kB 4.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105795 sha256=443db62d22019f886f8aa0d916ece46a1abc99ac0bbe4874040b9929180fd04e\n",
      "  Stored in directory: c:\\users\\bhawna kansal\\appdata\\local\\pip\\cache\\wheels\\46\\d2\\26\\84d0a1acdb9c6baccf7d28cf06962ec80529fe1ad938489983\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\slugify.exe' -> 'C:\\\\Python312\\\\Scripts\\\\slugify.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\python312\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: python-slugify in c:\\python312\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (2.2.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\python312\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\python312\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from requests->kaggle) (3.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhawna kansal\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle\n",
    "import json\n",
    "# %mkdir .kaggle\n",
    "# !touch .kaggle/kaggle.json\n",
    "kaggle_credentails = json.load(open(\"kaggle.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = kaggle_credentails[\"username\"]\n",
    "os.environ['KAGGLE_KEY'] = kaggle_credentails[\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%kaggle datasets download -d abdallahalidev/plantvillage-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"plantvillage-dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"plantvillage dataset\"))\n",
    "\n",
    "\n",
    "print(len(os.listdir(\"plantvillage dataset/segmented\")))\n",
    "print(os.listdir(\"plantvillage dataset/segmented\")[:5])\n",
    "\n",
    "print(len(os.listdir(\"plantvillage dataset/color\")))\n",
    "print(os.listdir(\"plantvillage dataset/color\")[:5])\n",
    "\n",
    "print(len(os.listdir(\"plantvillage dataset/grayscale\")))\n",
    "print(os.listdir(\"plantvillage dataset/grayscale\")[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(\"plantvillage dataset/color/Grape___healthy\")))\n",
    "print(os.listdir(\"plantvillage dataset/color/Grape___healthy\")[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'plantvillage dataset/color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'\n",
    "\n",
    "# Read the image\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "print(img.shape)\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Turn off axis numbers\n",
    "plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'\n",
    "\n",
    "# Read the image\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # Use 20% of data for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = data_gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(train_generator.num_classes, activation='softmax'))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch\n",
    "    epochs=5,  # Number of epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size  # Validation steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating model...\")\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    # Resize the image\n",
    "    img = img.resize(target_size)\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = np.array(img)\n",
    "    # Add batch dimension\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    # Scale the image values to [0, 1]\n",
    "    img_array = img_array.astype('float32') / 255.\n",
    "    return img_array\n",
    "\n",
    "# Function to Predict the Class of an Image\n",
    "def predict_image_class(model, image_path, class_indices):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_class_name = class_indices[predicted_class_index]\n",
    "    return predicted_class_name\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {v: k for k, v in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(class_indices, open('class_indices.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "image_path = '/content/test_apple_black_rot.JPG'\n",
    "#image_path = '/content/test_blueberry_healthy.jpg'\n",
    "#image_path = '/content/test_potato_early_blight.jpg'\n",
    "predicted_class_name = predict_image_class(model, image_path, class_indices)\n",
    "\n",
    "# Output the result\n",
    "print(\"Predicted Class Name:\", predicted_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('plant_disease_prediction_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
